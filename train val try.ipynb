{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f7145b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import albumentations\n",
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import timm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from glob import glob\n",
    "from zipfile import ZipFile\n",
    "from PIL import Image\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from albumentations import augmentations as A\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torchvision import models, transforms\n",
    "from torchmetrics.functional import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7096af76",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"D:\\Art DataBase\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c5da20f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(base_path, 'train', '*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a1dd5369",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = os.path.join(base_path, 'test', '*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3acf1dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = glob(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e1d42d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = glob(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "395ef8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a37f11af",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(os.path.join(base_path, 'metadata.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a5ac8bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_mean = (0.485, 0.456, 0.406)\n",
    "norm_std = (0.229, 0.224, 0.225)\n",
    "\n",
    "transforms = albumentations.Compose(\n",
    "    [A.Normalize(norm_mean, norm_std),\n",
    "     A.geometric.Resize(256, 256),\n",
    "     ToTensorV2()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9366b843",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The fit method(standardization) is calculating the mean and variance of \n",
    "#each of the features\n",
    "#present in our data. The transform\n",
    "#method is transforming all the features using the respective mean and variance.\n",
    "#labelencoder = Encode target labels with value between 0 and n_classes-1.\n",
    "enc = LabelEncoder()\n",
    "\n",
    "metadata['artist_cat'] = enc.fit_transform(metadata['artist'].astype(str))\n",
    "metadata['style_cat'] = enc.fit_transform(metadata['style'].astype(str))\n",
    "metadata['filename'] = enc.fit_transform(metadata['new_filename'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b8256c66",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>date</th>\n",
       "      <th>genre</th>\n",
       "      <th>pixelsx</th>\n",
       "      <th>pixelsy</th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>source</th>\n",
       "      <th>style</th>\n",
       "      <th>title</th>\n",
       "      <th>artist_group</th>\n",
       "      <th>in_train</th>\n",
       "      <th>new_filename</th>\n",
       "      <th>artist_cat</th>\n",
       "      <th>style_cat</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barnett Newman</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>abstract</td>\n",
       "      <td>15530.0</td>\n",
       "      <td>6911.0</td>\n",
       "      <td>9201912.0</td>\n",
       "      <td>wikiart</td>\n",
       "      <td>Color Field Painting</td>\n",
       "      <td>Uriel</td>\n",
       "      <td>train_only</td>\n",
       "      <td>True</td>\n",
       "      <td>102257.jpg</td>\n",
       "      <td>270</td>\n",
       "      <td>18</td>\n",
       "      <td>2512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barnett Newman</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>abstract</td>\n",
       "      <td>14559.0</td>\n",
       "      <td>6866.0</td>\n",
       "      <td>8867532.0</td>\n",
       "      <td>wikiart</td>\n",
       "      <td>Color Field Painting</td>\n",
       "      <td>Vir Heroicus Sublimis</td>\n",
       "      <td>train_only</td>\n",
       "      <td>True</td>\n",
       "      <td>75232.jpg</td>\n",
       "      <td>270</td>\n",
       "      <td>18</td>\n",
       "      <td>75733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kiri nichol</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9003.0</td>\n",
       "      <td>9004.0</td>\n",
       "      <td>1756681.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neoplasticism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test_only</td>\n",
       "      <td>False</td>\n",
       "      <td>32145.jpg</td>\n",
       "      <td>2255</td>\n",
       "      <td>81</td>\n",
       "      <td>27859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kiri nichol</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9003.0</td>\n",
       "      <td>9004.0</td>\n",
       "      <td>1942046.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neoplasticism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test_only</td>\n",
       "      <td>False</td>\n",
       "      <td>20304.jpg</td>\n",
       "      <td>2255</td>\n",
       "      <td>81</td>\n",
       "      <td>14703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kiri nichol</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9003.0</td>\n",
       "      <td>9004.0</td>\n",
       "      <td>1526212.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neoplasticism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test_only</td>\n",
       "      <td>False</td>\n",
       "      <td>836.jpg</td>\n",
       "      <td>2255</td>\n",
       "      <td>81</td>\n",
       "      <td>85029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103245</th>\n",
       "      <td>Jackson Pollock</td>\n",
       "      <td>1948.0</td>\n",
       "      <td>abstract</td>\n",
       "      <td>682.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>96405.0</td>\n",
       "      <td>wikiart</td>\n",
       "      <td>Action painting</td>\n",
       "      <td>Number 13A (Arabesque)</td>\n",
       "      <td>train_and_test</td>\n",
       "      <td>True</td>\n",
       "      <td>25525.jpg</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>20503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103246</th>\n",
       "      <td>Bernardo Strozzi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>religious painting</td>\n",
       "      <td>329.0</td>\n",
       "      <td>456.0</td>\n",
       "      <td>127594.0</td>\n",
       "      <td>wikiart</td>\n",
       "      <td>Baroque</td>\n",
       "      <td>St. Francis of Assisi</td>\n",
       "      <td>train_only</td>\n",
       "      <td>True</td>\n",
       "      <td>47038.jpg</td>\n",
       "      <td>296</td>\n",
       "      <td>12</td>\n",
       "      <td>44406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103247</th>\n",
       "      <td>Josef Sima</td>\n",
       "      <td>NaN</td>\n",
       "      <td>landscape</td>\n",
       "      <td>293.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>102519.0</td>\n",
       "      <td>wikiart</td>\n",
       "      <td>Surrealism</td>\n",
       "      <td>Maisons à la campagne II</td>\n",
       "      <td>train_and_test</td>\n",
       "      <td>False</td>\n",
       "      <td>7680.jpg</td>\n",
       "      <td>1163</td>\n",
       "      <td>120</td>\n",
       "      <td>77474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103248</th>\n",
       "      <td>Brett Whiteley</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>marina</td>\n",
       "      <td>293.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>167423.0</td>\n",
       "      <td>wikiart</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thebe's Revenge</td>\n",
       "      <td>train_and_test</td>\n",
       "      <td>True</td>\n",
       "      <td>9021.jpg</td>\n",
       "      <td>329</td>\n",
       "      <td>136</td>\n",
       "      <td>92375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103249</th>\n",
       "      <td>Amadeo de Souza-Cardoso</td>\n",
       "      <td>1913</td>\n",
       "      <td>landscape</td>\n",
       "      <td>293.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>77577.0</td>\n",
       "      <td>wikiart</td>\n",
       "      <td>Cubism</td>\n",
       "      <td>House Manhufe</td>\n",
       "      <td>train_only</td>\n",
       "      <td>True</td>\n",
       "      <td>36564.jpg</td>\n",
       "      <td>162</td>\n",
       "      <td>24</td>\n",
       "      <td>32768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103250 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         artist    date               genre  pixelsx  pixelsy  \\\n",
       "0                Barnett Newman  1955.0            abstract  15530.0   6911.0   \n",
       "1                Barnett Newman  1950.0            abstract  14559.0   6866.0   \n",
       "2                   kiri nichol  2013.0                 NaN   9003.0   9004.0   \n",
       "3                   kiri nichol  2013.0                 NaN   9003.0   9004.0   \n",
       "4                   kiri nichol  2013.0                 NaN   9003.0   9004.0   \n",
       "...                         ...     ...                 ...      ...      ...   \n",
       "103245          Jackson Pollock  1948.0            abstract    682.0    220.0   \n",
       "103246         Bernardo Strozzi     NaN  religious painting    329.0    456.0   \n",
       "103247               Josef Sima     NaN           landscape    293.0    512.0   \n",
       "103248           Brett Whiteley  1982.0              marina    293.0    512.0   \n",
       "103249  Amadeo de Souza-Cardoso    1913           landscape    293.0    512.0   \n",
       "\n",
       "        size_bytes   source                 style                     title  \\\n",
       "0        9201912.0  wikiart  Color Field Painting                     Uriel   \n",
       "1        8867532.0  wikiart  Color Field Painting     Vir Heroicus Sublimis   \n",
       "2        1756681.0      NaN         Neoplasticism                       NaN   \n",
       "3        1942046.0      NaN         Neoplasticism                       NaN   \n",
       "4        1526212.0      NaN         Neoplasticism                       NaN   \n",
       "...            ...      ...                   ...                       ...   \n",
       "103245     96405.0  wikiart       Action painting    Number 13A (Arabesque)   \n",
       "103246    127594.0  wikiart               Baroque     St. Francis of Assisi   \n",
       "103247    102519.0  wikiart            Surrealism  Maisons à la campagne II   \n",
       "103248    167423.0  wikiart                   NaN           Thebe's Revenge   \n",
       "103249     77577.0  wikiart                Cubism            House Manhufe    \n",
       "\n",
       "          artist_group  in_train new_filename  artist_cat  style_cat  filename  \n",
       "0           train_only      True   102257.jpg         270         18      2512  \n",
       "1           train_only      True    75232.jpg         270         18     75733  \n",
       "2            test_only     False    32145.jpg        2255         81     27859  \n",
       "3            test_only     False    20304.jpg        2255         81     14703  \n",
       "4            test_only     False      836.jpg        2255         81     85029  \n",
       "...                ...       ...          ...         ...        ...       ...  \n",
       "103245  train_and_test      True    25525.jpg        1000          3     20503  \n",
       "103246      train_only      True    47038.jpg         296         12     44406  \n",
       "103247  train_and_test     False     7680.jpg        1163        120     77474  \n",
       "103248  train_and_test      True     9021.jpg         329        136     92375  \n",
       "103249      train_only      True    36564.jpg         162         24     32768  \n",
       "\n",
       "[103250 rows x 15 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata[metadata.new_filename == train_data[0].split('\\\\')[-1]]['artist_cat'].to_numpy()[0]\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2e9efa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArtistDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, base_path, transforms=None):\n",
    "        self.base_path = base_path\n",
    "        self.data = glob(self.base_path)\n",
    "        self.metadata = pd.read_csv('D:\\Art DataBase\\metadata.csv')\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data[idx]\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(image=img)['image']\n",
    "        return img, torch.tensor(metadata[metadata.new_filename == img_path.split('\\\\')[-1]]['artist_cat'].to_numpy()[0])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cbe1ca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ArtistDataset(train_path, transforms=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bd7fe0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ArtistDataset(test_path, transforms=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ab7ef7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "54d7a8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = len(train_dataset) - train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1faf5420",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b1b3e4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=32,\n",
    "                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "53a8afef",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = DataLoader(dataset=val_dataset,\n",
    "                          batch_size=32,\n",
    "                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4b425c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                          batch_size=32,\n",
    "                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c118c2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model(model_name='resnet50', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "550107f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_fc = nn.Linear(in_features=2048, out_features=2319)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6ef0093d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = last_fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "81ce0e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = model.parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d9369df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = optim.SGD(params, lr = 1e-2)\n",
    "optimizer = torch.optim.Adam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0eb75742",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "373e1e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model(train_dataset[0][0].unsqueeze(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7d8b7e27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for i,data in enumerate(train_loader,0):    \n",
    "#    x, y = data\n",
    "#    logit = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "69c8ff19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10348/3589146567.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mJ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    131\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'step'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m             F.adam(params_with_grad,\n\u001b[0m\u001b[0;32m    134\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\_functional.py\u001b[0m in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m         \u001b[0mexp_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m         \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "#training and validation loops\n",
    "n_epochs = 1\n",
    "for epoch in range(n_epochs):\n",
    "    losses = list()\n",
    "    accuracies = list()\n",
    "    model.train() #because of dropout in train we want it\n",
    "    for i,data in enumerate(train_loader,0):\n",
    "        \n",
    "        \n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()            \n",
    "        \n",
    "        labels = labels.long()\n",
    "        \n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        J = loss(outputs, labels)\n",
    "        \n",
    "        #import pdb; pdb.set_trace() ##for debugging\n",
    "        \n",
    "        J.backward()\n",
    "        optimizer.step()\n",
    "      \n",
    "        losses.append(J.item())\n",
    "        accuracies.append(labels.eq(outputs.detach().argmax(dim=1).cpu()).float().mean())\n",
    "    \n",
    "        print(f'Epoch {epoch + 1}', end=', ')\n",
    "        print(f'train loss: {torch.tensor(losses).mean():.2f}', end=', ')\n",
    "        print(f'train acc: {torch.tensor(accuracies).mean():.9f}')\n",
    "    \n",
    "    losses = list()\n",
    "    model.eval()#because of dropout in eval we dont\n",
    "    for i,data in enumerate(val_loader,0):\n",
    "        \n",
    "        inputs, labels = data\n",
    "        labels = labels.long()\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()            \n",
    "        \n",
    "\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "        \n",
    "        #2 compute objecttive function (howw well the network does)\n",
    "        J = loss(outputs, labels)\n",
    "        \n",
    "        losses.append(J.item())\n",
    "        accuracies.append(labels.eq(outputs.detach().argmax(dim=1).cpu()).float().mean())\n",
    "    \n",
    "        print(f'Epoch {epoch + 1}', end=', ')\n",
    "        print(f'val loss: {torch.tensor(losses).mean():.2f}', end=', ')\n",
    "        print(f'val acc: {torch.tensor(accuracies).mean():.9f}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21baf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), os.path.join('D:\\Art DataBase\\models','tryandeval.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ae6371d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = model\n",
    "model.load_state_dict(torch.load(r'D:\\Art DataBase\\models\\tryandeval.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "69b7b900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 36 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
